{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FvnPu7eC45A9oC_ofz29sVz9JcSU8ry0",
      "authorship_tag": "ABX9TyOP/MPSvh2AWG4kGjVY0VBk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CanteroAlann/machine-learning-projects/blob/main/TrabajoPractico2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbi7jUGDFnv6"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt update\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "import pandas as pd\n",
        "import string\n",
        "import math as mt "
      ],
      "metadata": {
        "id": "MDVTzEcDG91T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the Spark Session\n",
        "spark= SparkSession \\\n",
        "    .builder \\\n",
        "    .getOrCreate()\n",
        "# create the Spark Context\n",
        "sc= spark.sparkContext"
      ],
      "metadata": {
        "id": "NUkD292VHiF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_review = pd.read_csv('/content/drive/MyDrive/tp1_orga/review-002.csv')\n",
        "df_review.sample(frac=0.4).to_parquet('review.parquet')\n",
        "df_user = pd.read_csv('/content/drive/MyDrive/tp1_orga/user-001.csv')\n",
        "df_user.sample(frac=0.3).to_parquet('user.parquet')"
      ],
      "metadata": {
        "id": "rDJGRxchHnHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "S17 (). La antigüedad promedio de los usuarios y el nombre del usuario más antiguo cuyas última review contenga la palabra ‘pizza’"
      ],
      "metadata": {
        "id": "Eum2bb34H3h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo dataset de usuarios\n",
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.read.parquet('user.parquet', header=True, inferSchema=True, multiLine=True)\n",
        "user_rdd = df.rdd\n",
        "# cargo dataset de reviews\n",
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.read.parquet('review.parquet', header=True, inferSchema=True, multiLine=True)\n",
        "review_rdd = df.rdd"
      ],
      "metadata": {
        "id": "-v-0trTyH7BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import date\n",
        "def antiguedad(fecha):\n",
        "  return (pd.to_datetime(date.today()) - pd.to_datetime(fecha, errors='coerce', format='%Y-%m-%d %H:%M:%S')).days"
      ],
      "metadata": {
        "id": "fmz4CFHkIJVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapeo de la siguiente manera \n",
        "# x[0] = user_id ; x[1] = name ; x[3] = antiquity \n",
        "user_with_antiquity=user_rdd.map(lambda x : (x[0],(x[1] ,antiguedad(x[3])))).cache()"
      ],
      "metadata": {
        "id": "4X0NdAaoIKqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funcion para calcular la antiguedad en años, meses y dias \n",
        "def func_date(number_of_days):\n",
        "  # Calculating years\n",
        "  years = number_of_days // 365\n",
        "  # Calculating months\n",
        "  months = (number_of_days - years *365) // 30\n",
        "  # Calculating days\n",
        "  days = mt.floor((number_of_days - years * 365 - months*30))\n",
        "  # Displaying results\n",
        "  print(\"Years = \", years)\n",
        "  print(\"Months = \", months)\n",
        "  print(\"Days = \", days)"
      ],
      "metadata": {
        "id": "GNVczg0fIYOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculo la antiguedad promedio \n",
        "func_date(user_with_antiquity.map(lambda x : (x[1][1])).mean())"
      ],
      "metadata": {
        "id": "t_1vpnT9Orbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cont_pizza(string):\n",
        "  return 'pizza' in str(string)"
      ],
      "metadata": {
        "id": "V2Qr45ZfIfPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapeo de la siguiente manera \n",
        "# x[0] = user_id\n",
        "# x[7] = texto de la review \n",
        "# x[8] = fecha de la review \n",
        "# luego uso reduceByKey para quedarme con la review mas reciente por usuario y luego filtro aquellas reviews que contienen 'pizza'\n",
        "last_review_with_pizza = review_rdd.map(lambda x :(x[0],(x[7],x[8]))).reduceByKey(lambda x,y : ((x[0] if x[1] > y[1] else y[0]),(x[1] if x[1]>y[1] else y[1]))).filter(lambda x : cont_pizza(x[1][0]))"
      ],
      "metadata": {
        "id": "__VSy-FfImG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora hago un inner join para quedarme con los usuarios cuyas ultimas reviews contienen \"pizza\"\n",
        "# luego hago un reduce para quedarme con el usuario mas antiguo\n",
        "user = user_with_antiquity.join(last_review_with_pizza).reduce(lambda x,y : x if x[1][0][1] > y[1][0][1] else y)\n",
        "# Rta final\n",
        "print(\"el usuario mas antiguo cuya review contiene 'pizza' es :\",user[1][0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbn4O0FdIqvP",
        "outputId": "90a0d0f7-ff83-419b-a323-1992ad55b99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el usuario mas antiguo cuya review contiene 'pizza' es : Gioia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "S20 (). Buscar la distancia mínima que existe entre dos locales de McDonald ‘s en el estado de LA (que no comparten dirección). ¿Cuál es la distancia?¿A qué ciudad/es pertenecen? ¿Cuáles son las direcciones de los locales?\n"
      ],
      "metadata": {
        "id": "YNzTcL21QlGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_business = pd.read_csv('/content/drive/MyDrive/tp1_orga/business.csv')\n",
        "df_business.to_parquet('business.parquet')"
      ],
      "metadata": {
        "id": "CQtZlPjgQmW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo dataset de negocios \n",
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.read.parquet('business.parquet', header=True, inferSchema=True, multiLine=True)\n",
        "business_rdd = df.rdd"
      ],
      "metadata": {
        "id": "Iqz7Ra-QQsao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funcion para calcular la distancia \n",
        "import math \n",
        "def distancia12(lat1, lon1, lat2, lon2):\n",
        "\n",
        "    lat1rad = math.radians(lat1)\n",
        "    lon1rad = math.radians(lon1)\n",
        "\n",
        "    lat2rad = math.radians(lat2)\n",
        "    lon2rad = math.radians(lon2)\n",
        "\n",
        "    #  Si las latitudes y longitudes son iguales se encuentran en el mismo sitio geografico\n",
        "    if lat1rad == lat2rad and lon1rad == lon2rad:\n",
        "        return 0\n",
        "\n",
        "    #  Calculo de la distancia P1 a P2\n",
        "    a = math.sin(lat1rad)*math.sin(lat2rad)\n",
        "    b = math.cos(lat1rad)*math.cos(lat2rad)*math.cos(lon2rad - lon1rad)\n",
        "    D = math.acos(a + b)  \n",
        "\n",
        "    d = 111.18*math.degrees(D) \n",
        "    \n",
        "    return d"
      ],
      "metadata": {
        "id": "g2xQiA-wQya-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtro por las condiciones pedidas por el enunciado y luego mapeo de la siguiente manera :\n",
        "# x[0] = business_id ; x[2] = address ; x[3] = city ; x[6] = latitude ; x[7] = longitude\n",
        "aux_rdd = business_rdd.filter(lambda x : x[4] == 'LA').filter(lambda x : x[1]==\"McDonald's\").map(lambda x : (x[0],x[2],x[3],x[6],x[7])).cache()"
      ],
      "metadata": {
        "id": "zjW4aNPNQ37m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# producto cartesiano \n",
        "mc_rdd = aux_rdd.cartesian(aux_rdd)\n",
        "# rdd auxiliar donde hago un mapeo para obtener lo siguiente :\n",
        "# x[0][1] = address 1 ; x[0][2] = city 1 ; x[1][1] = address 2 ; x[1][2] = city 2 \n",
        "cc = mc_rdd.map(lambda x : (x[0][1],x[0][2],x[1][1],x[1][2],distancia12(x[0][3],x[0][4],x[1][3],x[1][4])))"
      ],
      "metadata": {
        "id": "HVV6kveMQ8UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtro aquellas distancias que son 0 y luego busco los mcdonald's mas cercanos \n",
        "mcdonals_mas_cercanos = cc.filter(lambda x : x[4] > 0).reduce(lambda x,y : x if x[4] < y[4] else y)\n",
        "# respuesta final \n",
        "print(\"Direccion 1 : \",mcdonals_mas_cercanos[0],\" ; Direccion 2 : \",mcdonals_mas_cercanos[2],\" ; Ciudad : \",mcdonals_mas_cercanos[1],\" ; Distancia:\",mcdonals_mas_cercanos[4],\"km\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crLmWI8WRBsA",
        "outputId": "e023cc16-e77c-4f3b-e84b-ab04f3a3d466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Direccion 1 :  1212 Stumpf Blvd  ; Direccion 2 :  501 Westbank Expy  ; Ciudad :  Gretna  ; Distancia: 1.1583698947020564 km\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "S32 (). Yelp tiene la teoría de que quienes hacen las reviews más útiles en la plataforma son aquellos usuarios con más antigüedad. Para probar está hipótesis para cada review consiga la suma total de sus votos (funny + cool + useful) y correlacionela con la antigüedad del usuario al momento de hacer la review."
      ],
      "metadata": {
        "id": "yIG17AzZRcyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_review = pd.read_csv('/content/drive/MyDrive/tp1_orga/review-002.csv')\n",
        "df_review.sample(frac=0.2).to_parquet('review.parquet')"
      ],
      "metadata": {
        "id": "-mx6V1WDRdtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_user = pd.read_csv('/content/drive/MyDrive/tp1_orga/user-001.csv')\n",
        "df_user.sample(frac=0.2).to_parquet('user.parquet')"
      ],
      "metadata": {
        "id": "LQoOMqJATABs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo dataset de usuarios\n",
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.read.parquet('user.parquet', header=True, inferSchema=True, multiLine=True)\n",
        "user_rdd = df.rdd\n",
        "# cargo dataset de reviews\n",
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.read.parquet('review.parquet', header=True, inferSchema=True, multiLine=True)\n",
        "review_rdd = df.rdd"
      ],
      "metadata": {
        "id": "zei0w86ATEyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funcion para obtener la suma de votos \n",
        "def sum_(x,y,z):\n",
        "  return float(x) + float(y) + float(z)"
      ],
      "metadata": {
        "id": "l91p-YgJTyBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapeo de la siguiente manera \n",
        "# x[1] = user_id ; x[4],x[5],x[6] = usefull,funny,cool ; x[8] = date\n",
        "list_user_reviews =review_rdd.map(lambda x : (x[1],(sum_(x[4],x[5],x[6]),x[8])))\n",
        "# mapeo de la siguiente manera \n",
        "# x[0]= user_id ; x[3] = yelping_since\n",
        "list_users = user_rdd.map(lambda x : (x[0],x[3]))"
      ],
      "metadata": {
        "id": "pDiOkKOxT1C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inner join para asi unir cada user_id con su respectiva fecha de ingreso \n",
        "usefull_rdd = list_users.join(list_user_reviews)"
      ],
      "metadata": {
        "id": "yQdsdFdYT7gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funcion para obtener la antiguedad del usuario al momento de hacer la review \n",
        "def antiguedad_usuario(fecha_del_usuario,fecha_de_la_review):\n",
        "  return (pd.to_datetime(fecha_de_la_review, errors='coerce', format='%Y-%m-%d %H:%M:%S') - pd.to_datetime(fecha_del_usuario, errors='coerce', format='%Y-%m-%d %H:%M:%S')).days"
      ],
      "metadata": {
        "id": "cbV6rFk1UAgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora mapeo para quedarme con la antiguedad del usuario al momento de hacer la review \n",
        "# x[0] = user_id ; x[1][1][0] = suma de votos ; x[1][0] = fecha de ingreso del usuario ; x[1][1][1] = fecha de la review \n",
        "prom_rdd = usefull_rdd.map(lambda x: (x[0],x[1][1][0],antiguedad_usuario(x[1][0],x[1][1][1]))).cache()"
      ],
      "metadata": {
        "id": "G4sOpY-bUEbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculo el promedio de la suma de votos \n",
        "prom_votos = prom_rdd.map(lambda x: (x[1])).mean()\n",
        "# calculo el promedio de la antiguedad de los usuarios\n",
        "prom_antiguedad = prom_rdd.map(lambda x : (x[2])).mean() "
      ],
      "metadata": {
        "id": "lEuaS57oUHse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora mapeo para obtener los siguientes terminos de la siguiente formula \n",
        "\n",
        "\\begin{align}\n",
        "        {\\displaystyle r_{xy}={\\frac {\\sum _{i=1}^{n}\\left(x_{i}-{\\bar {x}}\\right)\\left(y_{i}-{\\bar {y}}\\right)}{{\\sqrt {\\sum _{i=1}^{n}\\left(x_{i}-{\\bar {x}}\\right)^{2}}}{\\sqrt {\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}}}}}}\n",
        "    \\end{align}\n",
        " donde\n",
        "\n",
        " (x[1]-prom_votos)*(x[2]-prom_antiguedad)  = $(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})$\n",
        "\n",
        " (x[1]-prom_votos)*(x[1]-prom_votos) = $(x_{i}-{\\bar {x}})^{2}$\n",
        "\n",
        " (x[2]-prom_antiguedad)*(x[2]-prom_antiguedad) = $(y_{i}-{\\bar {y}})^{2}$"
      ],
      "metadata": {
        "id": "IMQug664UaSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# con el reduce realizo cada sumatoria de la formula anterior \n",
        "x = prom_rdd.map(lambda x: ((x[1]-prom_votos)*(x[2]-prom_antiguedad),(x[1]-prom_votos)*(x[1]-prom_votos),(x[2]-prom_antiguedad)*(x[2]-prom_antiguedad))).reduce(lambda x,y : (x[0]+y[0],x[1]+y[1],x[2]+y[2]))"
      ],
      "metadata": {
        "id": "led05uCqUcBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# por ultimo hago las raices y la division para obtener el resultado final \n",
        "import math as mt \n",
        "corr = (x[0]/(mt.sqrt(x[1])*mt.sqrt(x[2])))\n",
        "corr"
      ],
      "metadata": {
        "id": "a5lrX_OUUk4r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}